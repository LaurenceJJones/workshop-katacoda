```yaml
MANDATORY: NO
TYPE: []NODE
```

```yaml{1,5}
nodes:
  - grok:
      pattern: "%{RFC3339:timestamp} %{IPORHOST:source_ip}"
      apply_on: message
    nodes:
```

Now, this is the heart of the parser, the `nodes`{{}}! In short, the `nodes`{{}} are a list of `node`{{}} objects that parse information out of the event. If they are successful, they will inform the event to be passed over to `s02-enrich`{{}} stage.

Before we head into the first node, what are we exactly trying to parse? Here are some example log lines from myapp.

```
2023-01-10T21:13:10Z 10.10.10.10 resource not found URI=(/favicon.ico)
2023-01-10T21:13:13Z 10.10.10.10 invalid login request USER=(test)
2023-01-10T21:13:15Z 10.10.10.10 invalid login request USER=(test)
2023-01-10T21:13:20Z 10.10.10.10 invalid login request USER=(admin)
```

As you can see from the logs, the first section is a datetime stamp followed by an internal IP address `10.10.10.10`{{}} (Since killercoda has multiple entry points I hardcoded the source_ip to `10.10.10.10` for this example)


So let's break down the first `node`{{}} in our `nodes`{{}} list!

```
nodes:
|_Start the nodes array
|  - grok:
|__'-' in yaml is an array item to which grok object key is supplied
  |    pattern: "%{RFC3339:timestamp} %{IPORHOST:source_ip}"
  |___ Within the grok object is a pattern which is the 'GROK' & 'RE2' string
  |    apply_on: message
  |___ Within the grok object is the apply_on which indicates which parsed key to apply the grok too.
```

But let's explain the `pattern`{{}} and how we came to use `apply_on: message`{{}}

GROK patterns can be complex, depending on your application logs. In this example, they are kept simple so you can get used to the syntax.

```
pattern: "%{RFC3339:timestamp} %{IPORHOST:source_ip}"
            |                    |_IPORHOST grok pattern is applied and if successful will be saved in evt.Parsed.source_ip
            |_RFC3339 grok pattern is applied and if successful will be saved in evt.Parsed.timestamp

```

Where do the `RFC3339`{{}} & `IPORHOST`{{}} grok patterns come from? By default, crowdsec imports a list of common grok patterns that are used [LINK](https://docs.crowdsec.net/docs/next/parsers/patterns)

Why do we need the `apply_on: message`{{}}?

Let's hop back to the `s00-raw`{{}} stage again and see the lines that set this.

```yaml{7,8}
#if it's not syslog, the type is the program
filter: "evt.Line.Labels.type != 'syslog'"
onsuccess: next_stage
name: crowdsecurity/non-syslog
#debug: true
statics:
  - parsed: message
    expression: evt.Line.Raw
  - parsed: program
    expression: evt.Line.Labels.type
  - meta: datasource_path
    expression: evt.Line.Src
  - meta: datasource_type
    expression: evt.Line.Module
```

>Where does evt.Line.Raw come from? That is straight from the crowdsec security engine, there are no stages before that set this.

So for our example one `evt.Line.Raw`{{}} would be `2023-01-10T21:13:13Z 10.10.10.10 invalid login request USER=(test)`{{}} hence we can `apply_on`{{}} the `message`{{}} key.

The first node `GROK`{{}} pattern will be successful since all log lines start with `timestamp ip`{{}}. Here is what we can parse so far!
```
line: 2023-01-10T21:13:13Z 10.10.10.10 invalid login request USER=(test)
        â”œ s00-raw
        |       â”œ ðŸŸ¢ crowdsecurity/non-syslog (first_parser)
        |       â”” ðŸ”´ crowdsecurity/syslog-logs
        â”œ s01-parse
        |       â”” ðŸŸ¢ username/myapp (+7 ~2)
        |               â”” update evt.Stage : s01-parse -> s02-enrich
        |               â”” create evt.Parsed.source_ip : 10.10.10.10
        |               â”” create evt.Parsed.timestamp : 2023-01-10T21:13:13Z
```

Let's add the `nodes`{{}} list and our first `node`{{}} to our parser!
```
echo "nodes:
  - grok:
      pattern: \"%{RFC3339:timestamp} %{IPORHOST:source_ip}\"
      apply_on: message
    nodes:" >> /etc/crowdsec/parsers/s01-parse/myapp.yaml
```{{exec}}

However! Some of you keen eye people might have seen there is a nested `nodes`{{}} property within the first `node`{{}}!

This is useful because we can add extra meta properties to the event instead of repeating ourselves.
